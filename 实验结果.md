# 实验结果
## 第一第二问
### 正常预测（完整）
```bash
Image: picture\bowl-3243264_1280.jpg
Clean:
Top 1: mortar (class 666), prob = 0.6269
Top 2: soup bowl (class 809), prob = 0.1710
Top 3: mixing bowl (class 659), prob = 0.1617
Top 4: ladle (class 618), prob = 0.0148
Top 5: wok (class 909), prob = 0.0083
Image: picture\butterflies-4327296_1280.jpg
Clean:
Top 1: monarch (class 323), prob = 0.2976
Top 2: ringlet (class 322), prob = 0.2515
Top 3: lycaenid (class 326), prob = 0.2484
Top 4: sulphur butterfly (class 325), prob = 0.0683
Top 5: lacewing (class 318), prob = 0.0671
Image: picture\camera-2169435_1280.jpg
Clean:
Top 1: reflex camera (class 759), prob = 0.9653
Top 2: lens cap (class 622), prob = 0.0294
Top 3: Polaroid camera (class 732), prob = 0.0051
Top 4: tripod (class 872), prob = 0.0001
Top 5: projector (class 745), prob = 0.0000
Image: picture\chartres-cathedral-1021517_1280.jpg
Clean:
Top 1: bell cote (class 442), prob = 0.5214
Top 2: church (class 497), prob = 0.4363
Top 3: analog clock (class 409), prob = 0.0292
Top 4: monastery (class 663), prob = 0.0034
Top 5: wall clock (class 892), prob = 0.0032
Image: picture\dandelion-851614_1280.jpg
Clean:
Top 1: bee (class 309), prob = 0.9984
Top 2: fly (class 308), prob = 0.0010
Top 3: apiary (class 410), prob = 0.0002
Top 4: honeycomb (class 599), prob = 0.0002
Top 5: ant (class 310), prob = 0.0001
Image: picture\elephant-1562127_1280.jpg
Clean:
Top 1: African elephant (class 386), prob = 0.5210
Top 2: tusker (class 101), prob = 0.4767
Top 3: Indian elephant (class 385), prob = 0.0020
Top 4: warthog (class 343), prob = 0.0000
Top 5: zebra (class 340), prob = 0.0000
Image: picture\example.jpg
Clean:
Top 1: giant panda (class 388), prob = 0.9996
Top 2: soccer ball (class 805), prob = 0.0001
Top 3: lesser panda (class 387), prob = 0.0001
Top 4: indri (class 384), prob = 0.0000
Top 5: dalmatian (class 251), prob = 0.0000
Image: picture\horse-769128_1280.jpg
Clean:
Top 1: sorrel (class 339), prob = 0.9530
Top 2: Arabian camel (class 354), prob = 0.0257
Top 3: hartebeest (class 351), prob = 0.0040
Top 4: Rhodesian ridgeback (class 159), prob = 0.0031
Top 5: boxer (class 242), prob = 0.0020
Image: picture\nature-3084703_1280.jpg
Clean:
Top 1: cock (class 7), prob = 0.9899
Top 2: hen (class 8), prob = 0.0101
Top 3: stinkhorn (class 994), prob = 0.0000
Top 4: partridge (class 86), prob = 0.0000
Top 5: crane bird (class 134), prob = 0.0000
Image: picture\nature-3358233_1280.jpg
Clean:
Top 1: rapeseed (class 984), prob = 1.0000
Top 2: wing (class 908), prob = 0.0000
Top 3: school bus (class 779), prob = 0.0000
Top 4: sunglasses (class 837), prob = 0.0000
Top 5: parachute (class 701), prob = 0.0000
Image: picture\pexels-dreamypixel-547115.jpg
Clean:
Top 1: alp (class 970), prob = 0.9042
Top 2: valley (class 979), prob = 0.0221
Top 3: mountain tent (class 672), prob = 0.0195
Top 4: tripod (class 872), prob = 0.0080
Top 5: volcano (class 980), prob = 0.0066
Image: picture\rabbits-2174679_1280.jpg
Clean:
Top 1: Persian cat (class 283), prob = 0.3120
Top 2: Angora (class 332), prob = 0.2331
Top 3: hare (class 331), prob = 0.0630
Top 4: corn (class 987), prob = 0.0296
Top 5: hamster (class 333), prob = 0.0280
Image: picture\shanghai-1029368_1280.jpg
Clean:
Top 1: water tower (class 900), prob = 0.6859
Top 2: airship (class 405), prob = 0.0551
Top 3: cab (class 468), prob = 0.0186
Top 4: crane (class 517), prob = 0.0120
Top 5: hair spray (class 585), prob = 0.0119
Image: picture\violin-924349_1280.jpg
Clean:
Top 1: violin (class 889), prob = 0.7174
Top 2: cello (class 486), prob = 0.2793
Top 3: acoustic guitar (class 402), prob = 0.0031
Top 4: banjo (class 420), prob = 0.0001
Top 5: electric guitar (class 546), prob = 0.0000
```
### 攻击运行
#### 正常预测
```bash
Image: picture\example.jpg
Clean:
Top 1: giant panda (class 388), prob = 0.9996
Top 2: soccer ball (class 805), prob = 0.0001
Top 3: lesser panda (class 387), prob = 0.0001
Top 4: indri (class 384), prob = 0.0000
Top 5: dalmatian (class 251), prob = 0.0000
```
#### FGSM
```bash
Adversarial (fgsm):
Top 1: giant panda (class 388), prob = 0.9368
Top 2: soccer ball (class 805), prob = 0.0243
Top 3: lesser panda (class 387), prob = 0.0043
Top 4: brown bear (class 294), prob = 0.0012
Top 5: teddy (class 850), prob = 0.0012
```
#### PGD（更强，更容易成功）：
```bash
Adversarial (pgd):
Top 1: soccer ball (class 805), prob = 1.0000
Top 2: volleyball (class 890), prob = 0.0000
Top 3: rugby ball (class 768), prob = 0.0000
Top 4: baseball (class 429), prob = 0.0000
Top 5: football helmet (class 560), prob = 0.0000
```
#### CW-L2（较慢，建议先用较小步数验证）：
```bash
Adversarial (cw):
Top 1: soccer ball (class 805), prob = 0.4585
Top 2: giant panda (class 388), prob = 0.4112
Top 3: teddy (class 850), prob = 0.0054
Top 4: dalmatian (class 251), prob = 0.0037
Top 5: tennis ball (class 852), prob = 0.0033
```
### 防御实验（对比攻击前和攻击后的模型预测结果）：
```bash
python defense_experiments.py --image ./picture/example.jpg --attacks fgsm pgd cw --eps_list 0.015686275 0.031372549
```
#### 模型与数据参数
| 参数             | 你的输入                      | 含义                          |
|----------------|---------------------------|-----------------------------|
| `--model_type` | `standard` (默认)           | 使用标准ResNet50模型（而非对抗训练的鲁棒模型） |
| `--image`      | `./picture/example.jpg`   | 测试的单张图片路径                   |
| `--attacks`    | `fgsm pgd`                | 要执行的攻击方法：FGSM和PGD           |
| `--eps_list`   | `0.015686275 0.031372549` | 扰动半径列表（分别对应 4/255 和 8/255）  |
#### 攻击参数
| 参数           | 默认值     | 含义         |
|--------------|---------|------------|
| `--alpha`    | `2/255` | PGD每步的步长   |
| `--steps`    | `10`    | PGD迭代步数    |
| `--cw_c`     | `1.0`   | CW攻击损失函数权重 |
| `--cw_kappa` | `0.0`   | CW攻击置信度参数  |
| `--cw_steps` | `100`   | CW攻击最大迭代步数 |
| `--cw_lr`    | `0.01`  | CW攻击学习率    |
#### 防御与检测参数
| 参数                     | 默认值     | 含义                       |
|------------------------|---------|--------------------------|
| `--detector_threshold` | `None`  | 特征检测器阈值（None则自动校准）       |
| `--calibrate_dir`      | `None`  | 用于阈值校准的干净样本目录            |
| `--calibrate_n`        | `100`   | 校准样本数量                   |
| `--calibrate_quantile` | `0.99`  | 阈值分位数（0.99 = 取99%分位，较保守） |
| `--use_jpeg`           | `False` | 是否启用JPEG压缩防御（你未启用）       |
| `--jpeg_quality`       | `75`    | JPEG压缩质量                 |
#### 输出详解
| 输出字段                           | 含义                             | 理想值          |
|--------------------------------|--------------------------------|--------------|
| **`attack_success`**           | 攻击成功率：对抗样本是否**成功改变**模型预测？      | 越高说明攻击越强     |
| **`preproc_defense_acc`**      | 预处理防御准确率：对抗样本经防御后是否**恢复**正确预测？ | 越高说明防御越强     |
| **`detector_clean_pass_rate`** | 干净样本通过率：正常样本**未被误检**为对抗样本的比例   | 应接近1.0（降低误报） |
| **`detector_adv_flag_rate`**   | 对抗样本检出率：对抗样本**被正确识别**的比例       | 应接近1.0（提高检出） |
| **`detector_attack_success`**  | 攻击成功且**未被检测**的比例（绕过率）          | 越低越好         |


### 对普通模型
```bash
attack=fgsm, eps=0.01569, attack_success=0.500, preproc_defense_acc=0.740, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.020, detector_attack_success=0.500
attack=fgsm, eps=0.03137, attack_success=0.520, preproc_defense_acc=0.600, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.000, detector_attack_success=0.520
attack=pgd, eps=0.01569, attack_success=0.920, preproc_defense_acc=0.740, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.200, detector_attack_success=0.720
attack=pgd, eps=0.03137, attack_success=1.000, preproc_defense_acc=0.620, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.520, detector_attack_success=0.480
attack=cw, eps=0.01569, attack_success=1.000, preproc_defense_acc=0.840, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.020, detector_attack_success=0.980
attack=cw, eps=0.03137, attack_success=1.000, preproc_defense_acc=0.840, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.020, detector_attack_success=0.980
attack=cw, eps=0.06275, attack_success=1.000, preproc_defense_acc=0.840, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.020, detector_attack_success=0.980
```

### 强健模型
```bash
attack=fgsm, eps=0.01569, attack_success=0.420, preproc_defense_acc=0.500, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.000, detector_attack_success=0.420
attack=fgsm, eps=0.03137, attack_success=0.620, preproc_defense_acc=0.340, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.000, detector_attack_success=0.620
attack=pgd, eps=0.01569, attack_success=0.540, preproc_defense_acc=0.480, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.000, detector_attack_success=0.540
attack=pgd, eps=0.03137, attack_success=0.800, preproc_defense_acc=0.320, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.000, detector_attack_success=0.800
attack=cw, eps=0.01569, attack_success=0.280, preproc_defense_acc=0.700, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.020, detector_attack_success=0.260
attack=cw, eps=0.03137, attack_success=0.280, preproc_defense_acc=0.700, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.020, detector_attack_success=0.260
attack=cw, eps=0.06275, attack_success=0.280, preproc_defense_acc=0.700, detector_clean_pass_rate=0.980, detector_adv_flag_rate=0.020, detector_attack_success=0.260
```

### 效果分析
在本实验中，我们分别在普通模型与强健模型上，采用 FGSM 与 PGD 两种典型基于梯度的对抗攻击方法，在不同扰动强度（ε = 0.01569 与 ε = 0.03137）的设置下评估了模型在无防御、仅采用预处理防御以及联合预处理与检测机制时的鲁棒性表现。总体来看，在相同扰动幅度下，PGD 攻击的破坏能力显著强于 FGSM：在普通模型上，当 ε = 0.01569 时，FGSM 的攻击成功率为 0.500，而 PGD 的攻击成功率高达 0.920；当 ε 增大至 0.03137 时，PGD 攻击几乎可以实现 100% 的成功率，反映出迭代式攻击相较于单步攻击对模型具有更强的威胁。

对于普通模型，从防御角度看，预处理防御在中等扰动强度下对分类性能具有一定修复能力：在 ε = 0.01569 时，无论针对 FGSM 还是 PGD，对抗样本在经过预处理后模型准确率均可恢复到 0.740，说明该类防御在较小扰动范围内能够有效缓解对抗噪声的影响。然而，当 ε 增大到 0.03137 时，预处理防御的效果明显退化，准确率分别降至 0.600（FGSM）和 0.620（PGD），表明该方法对大幅度扰动的鲁棒性有限。对抗样本检测模块在保持低误报率方面表现稳定：在所有设置下，检测器对干净样本的通过率均为 0.980，说明其对正常样本的干扰较小。但在召回对抗样本方面，不同攻击与扰动强度之间存在明显差异。对于 FGSM 攻击，检测器几乎无法有效识别对抗样本，在两档 ε 下的对抗样本标记率仅为 0.020 和 0.000；相比之下，对于 PGD 攻击，检测器在 ε = 0.01569 时能标记约 20% 的对抗样本，在 ε = 0.03137 时标记率提升至 0.520，说明随着扰动强度的增大，对抗样本在特征空间中与正常样本的分布差异更易被检测器捕捉，从而带来一定检测收益。综合预处理与检测两种防御机制的联合作用来看，在强攻击场景下防御仍然存在明显不足：以 PGD+大 ε 为例，虽然检测器能够识别超过一半的对抗样本，并辅以预处理防御将部分样本恢复为正确分类，但最终攻击成功率仍为 0.480，仅将原始 100% 的攻击成功率削弱一半左右；在 PGD+小 ε 场景下，联合防御后的攻击成功率依旧高达 0.720，模型鲁棒性仍然较为脆弱。

在强健模型上，基础鲁棒性相较普通模型整体有所提升，尤其体现在迭代式 PGD 攻击下：当 ε = 0.01569 时，PGD 的攻击成功率由普通模型上的 0.920 降至 0.540；当 ε = 0.03137 时，从 1.000 降至 0.800，表明强健模型在面对较强攻击时能够显著压制部分对抗样本的成功率。对于 FGSM，小扰动 ε = 0.01569 下的攻击成功率从 0.500 降至 0.420，同样体现出一定鲁棒性提升；但在较大扰动 ε = 0.03137 时，FGSM 的攻击成功率反而从 0.520 升至 0.620，说明强健模型在某些方向上仍存在易受单步大幅度扰动影响的脆弱性。

值得注意的是，在强健模型上，沿用同一预处理防御策略的收益明显弱于普通模型：在四种攻击设置下，对抗样本经预处理后的准确率仅为 0.500、0.340（FGSM）以及 0.480、0.320（PGD），均显著低于普通模型对应的 0.740/0.600 与 0.740/0.620。这表明预处理模块与强健模型所学习到的对抗鲁棒特征分布并不完全匹配，其在普通模型上表现出的“纠偏”能力并不能直接迁移到强健模型上。另一方面，检测器在强健模型上的表现也发生了明显退化：虽然对干净样本的通过率仍保持在 0.980，但在所有攻击与扰动强度设置下，对抗样本标记率均为 0.000，即检测器几乎无法在强健模型的特征空间中区分正常样本与对抗样本。结合结果可以看出，在强健模型场景下，预处理与检测模块几乎未能进一步降低攻击成功率，对强健模型的增益十分有限。

在此基础上，我们进一步考察了优化式 CW 攻击在两类模型上的表现。对于普通模型，在 ε = 0.01569、0.03137 与 0.06275 三档扰动强度下，CW 攻击在无防御情形下的攻击成功率均为 1.000，表明该攻击能够在极高概率上找到有效对抗样本。即便引入预处理防御后，对抗样本的分类准确率也仅能提升至约 0.840，且在三档 ε 下基本保持不变，说明 CW 生成的扰动更具针对性，预处理难以显著削弱其破坏效果。与此同时，检测器对干净样本的通过率仍稳定在 0.980，但对 CW 对抗样本的标记率仅约为 0.020，最终攻击成功率仍高达 0.980，整体防御体系对 CW 攻击几乎无实质抑制作用。

与此形成对比的是，在强健模型上，CW 攻击的基础成功率显著降低：在相同三档 ε 下，攻击成功率稳定在 0.280，表明对抗训练等鲁棒化手段能够有效压制优化式攻击的成功率。对抗样本经预处理后，模型准确率进一步提升至 0.700，显示出预处理在强健模型的特征空间中仍具有一定纠偏能力。检测器在该场景下对干净样本的通过率依旧为 0.980，对 CW 对抗样本的标记率约为 0.020，使最终攻击成功率略微下降至 0.260。整体而言，强健模型在 CW 攻击下展现出比普通模型显著更高的鲁棒性，但现有检测器仅能带来极其有限的额外收益。

综合普通模型与强健模型的两组实验结果可以得到如下结论：
1. 在相同扰动约束下，PGD 等迭代式攻击以及 CW 等优化式攻击始终比单步 FGSM 具有更强的攻击能力，是评估模型鲁棒性的更严格基准；
2. 对于普通模型，预处理防御在中等幅度对抗扰动下具有一定缓解作用，但其防御效果随扰动强度增大快速下降；检测器在保证低误报的同时，对弱扰动和 FGSM 类型对抗样本的识别能力不足，仅在强 PGD 攻击场景下表现出有限的检测效果；
3. 引入强健模型可以显著降低在 PGD 等强攻击下的基础攻击成功率，但同时也削弱了原有预处理与检测模块的增益，表明不同防御组件之间存在明显的相互作用与适配问题；
4. 整体而言，单一或简单串联的预处理与检测机制难以在强攻击场景下将攻击成功率压制到满意水平，后续需要结合对抗训练、联合优化检测器与分类器等更系统性的防御策略，以在保持低误报的同时进一步提升模型的整体对抗鲁棒性。

## 迁移攻击
```bash
python blackbox_transfer.py --image_dir picture --attacks fgsm pgd cw --eps 0.031372549 --alpha 0.007843137 --steps 10 --cw_c 1.0 --cw_kappa 0.0 --cw_steps 50 --cw_lr 0.01 --visualize_n 10
Attack/Model    VGG19   ViT     Swin
FGSM    38.0%   14.0%   26.0%
PGD     46.0%   10.0%   36.0%
CW      2.0%    2.0%    8.0%
```
### 结果分析
**结果整体解读**

表中各百分数反映了在相同实验设置下，不同攻击方法对三种模型架构的破坏效果。可以观察到：
- 对于 **VGG19**，FGSM 和 PGD 的攻击成功率分别为 38.0% 与 46.0%，明显高于 CW 的 2.0%，说明传统卷积网络在本实验设置下对基于梯度的一步与多步攻击（FGSM/PGD）更为脆弱，而对 CW 攻击表现出较强的鲁棒性或极低的迁移性。
- 对于 **ViT**，FGSM 与 PGD 的攻击成功率分别为 14.0% 和 10.0%，均显著低于 VGG19，对 CW 的攻击成功率仅为 2.0%。整体来看，ViT 在三种攻击下均取得了最低的攻击成功率，体现出相对更好的对抗鲁棒性，这与近年来一些工作中关于 Transformer 架构在损失景观平滑性和全局建模能力方面的优势相吻合。
- 对于 **Swin**，FGSM 与 PGD 的攻击成功率分别为 26.0% 与 36.0%，介于 VGG19 和 ViT 之间，而 CW 的攻击成功率为 8.0%，高于 ViT 但仍明显低于 FGSM/PGD。说明层级化的 Transformer 结构在对抗鲁棒性上处于“折中”位置：相较传统卷积网络有所提升，但整体仍不及标准 ViT。

从攻击方法的维度看：
- **PGD 行**（46.0%、10.0%、36.0%）整体上对三种模型的破坏力高于或接近 FGSM 行（38.0%、14.0%、26.0%），符合迭代式攻击相较单步攻击更强的普遍结论。
- **CW 行** 的数值（2.0%、2.0%、8.0%）在三种模型上均远低于 FGSM/PGD，对普通卷积网络与 Transformer 的攻击成功率均处于极低水平。这一现象结合你前面基于单模型的实验结果，可以合理解释为：在白盒场景下，CW 攻击可以达到极高的成功率，但在当前表格所对应的场景（更可能是跨模型迁移或不同架构下的泛化攻击）中，其**迁移性较差**，导致在其他模型上观测到的攻击成功率显著衰减。

**可用于报告的总结性表述示例**
在对三种代表性模型架构（VGG19、ViT 与 Swin Transformer）进行横向对比时，可以进一步观察到基于卷积与基于 Transformer 的网络在对抗鲁棒性上的系统性差异。总体而言，VGG19 在 FGSM 与 PGD 攻击下的攻击成功率分别达到 38.0% 与 46.0%，明显高于 ViT 与 Swin，对应地反映出传统卷积网络在本实验设置下对基于梯度的一步与多步攻击更加敏感。相比之下，ViT 在三种攻击下的攻击成功率分别仅为 14.0%、10.0% 和 2.0%，在所有配置中均取得最低值，表明其全局自注意力机制和更平滑的特征表示在一定程度上提升了对抗鲁棒性；Swin 的表现介于二者之间（如 FGSM 与 PGD 下攻击成功率为 26.0% 与 36.0%），呈现出“折中型”的鲁棒性水平。

从攻击方法的角度来看，PGD 在各模型上的攻击成功率普遍不低于 FGSM，印证了迭代式攻击普遍强于单步攻击的观察。而 CW 攻击在三种模型上的攻击成功率仅为 2.0%–8.0%，显著低于 FGSM 与 PGD。这一结果与前文在单模型白盒设定中 CW 攻击几乎可以实现 100% 成功率的现象形成鲜明对比，说明在本表所对应的评测设定中（例如跨模型迁移或异构架构间的泛化攻击），CW 生成的对抗样本**迁移性有限**，在其他模型上难以保持同等强度的破坏效果。因此，从综合安全性角度出发，PGD 及类似的迭代式攻击更适合作为评估模型跨架构鲁棒性的“强基准”，而 CW 攻击在迁移场景中的威胁则相对较弱。