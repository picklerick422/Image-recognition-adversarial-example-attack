# 实验报告
## 三、防御手段

### 3.1 对比鲁棒模型和非鲁棒模型
**1. 先对比两个模型到底哪里好、哪里差**

你给的两组结果（我整理成表）：

**普通模型（standard）：**

```text
attack=fgsm, eps=0.01569, attack_success=0.571, preproc_defense_acc=0.714
attack=fgsm, eps=0.03137, attack_success=0.571, preproc_defense_acc=0.500
attack=pgd,  eps=0.01569, attack_success=0.929, preproc_defense_acc=0.714
attack=pgd,  eps=0.03137, attack_success=1.000, preproc_defense_acc=0.429
```

**鲁棒模型（robust）：**

```text
attack=fgsm, eps=0.01569, attack_success=0.500, preproc_defense_acc=0.429
attack=fgsm, eps=0.03137, attack_success=0.571, preproc_defense_acc=0.286
attack=pgd,  eps=0.01569, attack_success=0.571, preproc_defense_acc=0.429
attack=pgd,  eps=0.03137, attack_success=0.857, preproc_defense_acc=0.357
```

分开看两个指标：

- **纯攻击（无输入预处理）效果 → 看 `attack_success`：**
  - FGSM 0.01569：0.571 → 0.500（robust 稍微好一点）
  - FGSM 0.03137：0.571 → 0.571（差不多）
  - PGD  0.01569：0.929 → 0.571（robust 明显好很多）
  - PGD  0.03137：1.000 → 0.857（robust 好一些）

  结论：**在“纯攻击无防御”这个维度上，鲁棒模型整体是更抗 PGD 的，并不是更差。**

- **加上输入预处理后的效果 → 看 `preproc_defense_acc`：**
  - FGSM 0.01569：0.714 → 0.429（robust 反而更差）
  - FGSM 0.03137：0.500 → 0.286
  - PGD  0.01569：0.714 → 0.429
  - PGD  0.03137：0.429 → 0.357

  结论：**在“叠加你的平滑+量化(+JPEG)预处理”之后，鲁棒模型确实表现更差。**

所以真正的情况是：

- 如果只看“攻击成功率”：鲁棒模型比普通模型强（尤其 PGD）。
- 如果看“叠加你这套输入预处理后的准确率”：鲁棒模型被你这套预处理搞得更糟。

你说的“都直接能完全攻击成功了”，更多是针对“加了预处理以后整体感觉不好”，而不是单看 `attack_success`。

---

**2. 为什么鲁棒模型 + 你的预处理防御反而更差？**

主要有三点原因：

1. **鲁棒模型已经针对扰动做过优化，你的预处理在“多此一举，甚至破坏训练分布”**

   - 对普通模型：
     - 原来对扰动没有鲁棒性；
     - 你的平滑 + 量化可以“抹掉部分对抗噪声”，让模型恢复不少正确分类，因此 `preproc_defense_acc` 看起来很高。
   - 对对抗训练模型：
     - 模型本身已经学会对一类扰动保持稳定；
     - 你再做强平滑 + 量化，会把**干净的细节也抹掉**，把特征从模型训练时看到的分布上“推开”，结果是：
       - 干净样本准确率下降；
       - 对抗样本上，预处理抹掉的信息可能比“剩余的对抗噪声”还多，整体变差。

   所以，同一套预处理对普通模型是“有益的干预”，对鲁棒模型可能就是“损伤性的干预”。

2. **你的预处理是针对 standard 模型调的，没有专门为 robust 模型调参数**

   - 比如平滑核大小、量化等级、是否开启 JPEG 以及质量；
   - 对 standard 模型，你是一路试下来觉得 3×3 平滑、16 级量化还不错；
   - 对 robust 模型，这些参数可能应该更弱（例如更轻的平滑、更高的量化精度），否则对鲁棒模型来说损伤太大。

3. **数据集与鲁棒模型训练设置不完全一致**

   - RobustBench 的 ImageNet 鲁棒模型是按特定的攻击（常见是 AutoAttack / PGD）和特定 ε（例如 4/255）训练的；
   - 你现在在一小批“picture 文件夹里的自然图”（部分可能不是标准 ImageNet 分布）上，用 FGSM / 自定义 PGD 配置做攻击；
   - 这种轻微的分布差异 + 非完全对齐的攻击设置，会让“鲁棒优势”看起来没有那么明显；
   - 再叠加你没为鲁棒模型调过的预处理，自然就出现“表面上更差”的现象。

---

**3. 怎么在报告里解释这个现象比较合理**

你可以这样写：

- 在“纯攻击无防御”条件下，对抗训练 ResNet50 相比标准 ResNet50：  
  - 在 PGD 攻击下明显降低了攻击成功率（例如从 0.929/1.000 降到 0.571/0.857），说明对抗训练确实提高了模型的基本鲁棒性。
- 当叠加简单的输入预处理（平滑+量化+JPEG）时：
  - 对标准模型，该预处理可以抑制高频对抗噪声，从而恢复部分分类精度；
  - 对对抗训练模型，该预处理反而会破坏模型在训练时学到的鲁棒特征，使输入偏离训练分布，因此表现反而更差。
- 这表明：
  - **对抗训练与简单输入预处理之间有一定“冲突”**，不能简单“叠加”就一定更好；
  - 对抗训练模型需要“专门设计或重新调参”的预处理方法，而不能直接沿用为标准模型调好的那一套。

一句话总结给老师看就是：

> 对抗训练模型在“纯攻击无防御”条件下确实更鲁棒，但当直接叠加为标准模型设计的平滑+量化预处理时，反而会破坏鲁棒模型的特征分布，使整体表现下降。这说明防御手段之间并非简单可叠加，需要针对具体模型与训练方式专门设计和调参。

如果你愿意，我们还可以再做一个小实验：

- 对鲁棒模型只做“轻量版”的预处理（例如去掉平滑，只保留轻微量化），看看 `preproc_defense_acc` 是否会有所恢复；
- 或者对鲁棒模型只评估 `attack_success` 不看 `preproc_defense_acc`，把它单独作为“第三种防御手段：对抗训练”来展示，这样结构更清晰。