#!/usr/bin/env python3
"""
å¯¹æŠ—æ”»å‡»å¯è§†åŒ–åˆ†æå™¨ v6.0 (ç»ˆæä¿®å¤ç‰ˆ)
- âœ… å®Œå…¨å¤åˆ» ResNet.py çš„æ¨¡å‹åŠ è½½æ–¹å¼ (pretrained=True)
- âœ… ä½¿ç”¨æ—§ç‰ˆ IMAGENET1K_V1 æƒé‡ï¼Œä¸ ResNet.py ä¿æŒä¸€è‡´
- âœ… å…¨å±€å®šä¹‰CPUå¼ é‡ mean/stdï¼Œæ¯æ¬¡åŠ¨æ€è½¬æ¢
- âœ… æ¶ˆé™¤æ‰€æœ‰ä¸ ResNet.py çš„å®ç°å·®å¼‚
"""

from __future__ import annotations

import argparse
import json
import warnings
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Optional, Tuple

import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn.functional as F
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
from torchvision.utils import save_image

# ============= å±è”½Unicodeå­—ä½“è­¦å‘Š =============
warnings.filterwarnings("ignore", "Glyph.*missing from font", UserWarning)


# ============= æ”»å‡»å‡½æ•°å®ç°ï¼ˆä¿æŒä¸å˜ï¼‰ =============
def normalize_batch(x: torch.Tensor, mean: torch.Tensor, std: torch.Tensor) -> torch.Tensor:
    if mean.ndim != 1 or std.ndim != 1:
        raise ValueError("mean/std must be 1D tensors with shape [C]")
    if x.ndim != 4:
        raise ValueError("x must be a 4D tensor with shape [N, C, H, W]")
    mean = mean.to(device=x.device, dtype=x.dtype).view(1, -1, 1, 1)
    std = std.to(device=x.device, dtype=x.dtype).view(1, -1, 1, 1)
    return (x - mean) / std


def fgsm_attack(
        model: torch.nn.Module,
        x: torch.Tensor,
        y_true: torch.Tensor,
        *,
        eps: float,
        mean: torch.Tensor,
        std: torch.Tensor,
) -> torch.Tensor:
    x_in = x.detach().clone().requires_grad_(True)
    logits = model(normalize_batch(x_in, mean, std))
    loss = F.cross_entropy(logits, y_true)
    grad = torch.autograd.grad(loss, x_in, only_inputs=True)[0]
    x_adv = x_in + eps * grad.sign()
    return x_adv.clamp(0.0, 1.0).detach()


def pgd_linf_attack(
        model: torch.nn.Module,
        x: torch.Tensor,
        y_true: torch.Tensor,
        *,
        eps: float,
        alpha: float,
        steps: int,
        mean: torch.Tensor,
        std: torch.Tensor,
        random_start: bool = True,
) -> torch.Tensor:
    x_orig = x.detach()
    if random_start:
        x_adv = (x_orig + torch.empty_like(x_orig).uniform_(-eps, eps)).clamp(0.0, 1.0)
    else:
        x_adv = x_orig.clone()

    for _ in range(int(steps)):
        x_adv = x_adv.detach().clone().requires_grad_(True)
        logits = model(normalize_batch(x_adv, mean, std))
        loss = F.cross_entropy(logits, y_true)
        grad = torch.autograd.grad(loss, x_adv, only_inputs=True)[0]

        x_adv = x_adv + alpha * grad.sign()
        x_adv = torch.max(torch.min(x_adv, x_orig + eps), x_orig - eps)
        x_adv = x_adv.clamp(0.0, 1.0)

    return x_adv.detach()


def _atanh(x: torch.Tensor) -> torch.Tensor:
    return 0.5 * (torch.log1p(x) - torch.log1p(-x))


@dataclass(frozen=True)
class CWResult:
    x_adv: torch.Tensor
    success: torch.Tensor


def cw_l2_attack(
        model: torch.nn.Module,
        x: torch.Tensor,
        y_true: torch.Tensor,
        *,
        mean: torch.Tensor,
        std: torch.Tensor,
        c: float = 1.0,
        kappa: float = 0.0,
        steps: int = 1000,
        lr: float = 1e-2,
        targeted: bool = False,
        y_target: Optional[torch.Tensor] = None,
) -> CWResult:
    if targeted and y_target is None:
        raise ValueError("y_target must be provided when targeted=True")

    x0 = x.detach().clamp(0.0, 1.0)
    eps = 1e-6
    x0_tanh = x0 * (1.0 - 2.0 * eps) + eps
    w0 = _atanh(x0_tanh * 2.0 - 1.0).detach()
    w = w0.clone().requires_grad_(True)

    optimizer = torch.optim.Adam([w], lr=lr)

    best_adv = x0.clone()
    best_l2 = torch.full((x0.shape[0],), float("inf"), device=x0.device, dtype=x0.dtype)
    best_success = torch.zeros((x0.shape[0],), device=x0.device, dtype=torch.bool)

    y_cmp = y_target if targeted else y_true

    for _ in range(int(steps)):
        x_adv = 0.5 * (torch.tanh(w) + 1.0)
        logits = model(normalize_batch(x_adv, mean, std))

        num_classes = logits.shape[1]
        y_onehot = F.one_hot(y_cmp, num_classes=num_classes).to(dtype=logits.dtype)

        real = (logits * y_onehot).sum(dim=1)
        other = (logits - 1e4 * y_onehot).amax(dim=1)

        if targeted:
            f = torch.clamp(other - real + kappa, min=0.0)
            success = (logits.argmax(dim=1) == y_cmp)
        else:
            f = torch.clamp(real - other + kappa, min=0.0)
            success = (logits.argmax(dim=1) != y_true)

        l2 = (x_adv - x0).view(x0.shape[0], -1).pow(2).sum(dim=1)
        loss = (l2 + c * f).sum()

        optimizer.zero_grad(set_to_none=True)
        loss.backward()
        optimizer.step()

        improved = success & (l2 < best_l2)
        if improved.any():
            best_l2 = torch.where(improved, l2, best_l2)
            best_success = best_success | improved
            best_adv = torch.where(improved.view(-1, 1, 1, 1), x_adv.detach(), best_adv)

    final_adv = torch.where(best_success.view(-1, 1, 1, 1), best_adv, (0.5 * (torch.tanh(w) + 1.0)).detach())
    return CWResult(x_adv=final_adv, success=best_success)


# ============= å…¨å±€å˜é‡ï¼ˆä¸ResNet.pyå®Œå…¨ä¸€è‡´ï¼‰ =============
# âœ… åœ¨æ¨¡å—çº§åˆ«å®šä¹‰CPUå¼ é‡ï¼Œä¸ResNet.pyå®Œå…¨ç›¸åŒ
mean = torch.tensor([0.485, 0.456, 0.406])
std = torch.tensor([0.229, 0.224, 0.225])
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
])


# ============= å¯è§†åŒ–æ ¸å¿ƒç±» =============
class AttackVisualizer:
    def __init__(self, model: torch.nn.Module, device: torch.device,
                 imagenet_classes: list = None):
        self.model = model
        self.device = device

        # âœ… ä½¿ç”¨ torchmetrics è®¡ç®—SSIM
        try:
            from torchmetrics.image import StructuralSimilarityIndexMeasure
            self.ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)
            self.ssim_available = True
        except ImportError:
            print("âš ï¸  warning: torchmetricsæœªå®‰è£…ï¼ŒSSIMå°†æ— æ³•è®¡ç®—")
            print("  è¯·è¿è¡Œ: pip install torchmetrics")
            self.ssim_available = False

        # åŠ è½½ç±»åˆ«æ ‡ç­¾
        self.imagenet_classes = imagenet_classes or self._load_imagenet_classes()

    def _load_imagenet_classes(self) -> list:
        """åŠ è½½ImageNetç±»åˆ«æ ‡ç­¾"""
        try:
            import urllib.request
            url = "https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
            classes = urllib.request.urlopen(url, timeout=5).read().decode().strip().split('\n')
            return classes
        except:
            return [f"class_{i}" for i in range(1000)]

    def denormalize(self, x: torch.Tensor) -> torch.Tensor:
        """åå½’ä¸€åŒ–åˆ°[0,1]"""
        # âœ… ä½¿ç”¨å…¨å±€CPUå¼ é‡ï¼Œæ¯æ¬¡åŠ¨æ€è½¬æ¢
        mean_device = mean.to(device=x.device, dtype=x.dtype).view(1, 3, 1, 1)
        std_device = std.to(device=x.device, dtype=x.dtype).view(1, 3, 1, 1)
        return torch.clamp(x * std_device + mean_device, 0.0, 1.0)

    def predict(self, x: torch.Tensor) -> Tuple[int, str, float]:
        """âœ… ä¸ResNet.pyå®Œå…¨ä¸€è‡´çš„æ¨ç†é€»è¾‘"""
        with torch.no_grad():
            # ä½¿ç”¨å…¨å±€CPUå¼ é‡ï¼Œæ¯æ¬¡åŠ¨æ€è½¬æ¢ï¼ˆä¸ResNet.pyå®Œå…¨ç›¸åŒï¼‰
            mean_device = mean.to(device=x.device, dtype=x.dtype)
            std_device = std.to(device=x.device, dtype=x.dtype)

            logits = self.model(normalize_batch(x, mean_device, std_device))
            probs = F.softmax(logits, dim=1)
            pred_id = probs.argmax(dim=1).item()
            confidence = probs[0, pred_id].item()
            class_name = self.imagenet_classes[pred_id]
        return pred_id, class_name, confidence

    def calculate_metrics(self, x_clean: torch.Tensor, x_adv: torch.Tensor) -> Dict:
        """è®¡ç®—æ”»å‡»çš„å®šé‡æŒ‡æ ‡"""
        diff = x_adv - x_clean

        # LpèŒƒæ•°
        l_inf = torch.max(torch.abs(diff)).item()
        l_2 = torch.norm(diff, p=2).item()
        l_1 = torch.norm(diff, p=1).item()

        # âœ… SSIMè®¡ç®—
        if self.ssim_available:
            ssim_score = self.ssim_metric(x_clean, x_adv).item()
        else:
            ssim_score = 0.0

        # PSNRè®¡ç®—
        mse = torch.mean(diff ** 2).item()
        psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 1e-10 else 100.0

        # æ‰°åŠ¨åƒç´ æ¯”ä¾‹
        perturbed_pixels = (torch.abs(diff) > 1 / 255).float().mean().item() * 100

        # é«˜é¢‘æ‰°åŠ¨æ¯”ä¾‹
        fft_diff = torch.fft.fft2(diff[0])
        high_freq_ratio = (torch.abs(fft_diff) > torch.mean(torch.abs(fft_diff))).float().mean().item() * 100

        return {
            "Lâˆ (pixel)": l_inf,
            "L2": l_2,
            "L1": l_1,
            "SSIM": ssim_score,
            "PSNR": psnr,
            "Perturbed Pixels %": perturbed_pixels,
            "High Freq Ratio %": high_freq_ratio,
        }

    def visualize_attack_grid(self, x_clean: torch.Tensor,
                              results: Dict[str, Dict],
                              save_path: Path = None):
        """ç”Ÿæˆæ”»å‡»æ•ˆæœå›¾ç½‘æ ¼"""
        n_attacks = len(results)
        fig = plt.figure(figsize=(4 * 3, 4 * n_attacks))

        x_clean_denorm = self.denormalize(x_clean).squeeze()

        for idx, (attack_name, result) in enumerate(results.items()):
            x_adv = result["x_adv"]
            x_adv_denorm = self.denormalize(x_adv).squeeze()
            diff = (x_adv - x_clean).squeeze()

            clean_id = result["pred_clean"][0]
            adv_id = result["pred_adv"][0]
            success = "SUCCESS" if clean_id != adv_id else "FAILED"

            # Row 1: åŸå›¾ vs å¯¹æŠ—æ ·æœ¬
            ax1 = plt.subplot(n_attacks, 3, idx * 3 + 1)
            self._plot_image_pair(ax1, x_clean_denorm, x_adv_denorm,
                                  "Original", "Adversarial")

            # Row 2: æ‰°åŠ¨å›¾ Ã—10
            ax2 = plt.subplot(n_attacks, 3, idx * 3 + 2)
            diff_10x = torch.clamp(x_clean_denorm + 10 * diff, 0, 1)
            self._plot_image(ax2, diff_10x, "Perturbation Ã—10")

            # Row 3: æ‰°åŠ¨å›¾ Ã—50
            ax3 = plt.subplot(n_attacks, 3, idx * 3 + 3)
            diff_50x = torch.clamp(x_clean_denorm + 50 * diff, 0, 1)
            self._plot_image(ax3, diff_50x, "Perturbation Ã—50")

            fig.text(0.5, 1 - (idx * (1 / n_attacks) - 0.02),
                     f"{attack_name.upper()} Attack - {success}",
                     ha='center', va='top', fontsize=14, fontweight='bold')

        plt.tight_layout(rect=[0, 0, 1, 0.98])
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        print(f"  å·²ä¿å­˜: {save_path}")

    def _plot_image(self, ax, img_tensor, title):
        img_np = img_tensor.permute(1, 2, 0).cpu().numpy()
        img_np = np.clip(img_np, 0, 1)
        ax.imshow(img_np)
        ax.set_title(title, fontsize=11)
        ax.axis('off')

    def _plot_image_pair(self, ax, img1, img2, title1, title2):
        img_np = torch.cat([img1, img2], dim=2).permute(1, 2, 0).cpu().numpy()
        img_np = np.clip(img_np, 0, 1)
        ax.imshow(img_np)
        ax.set_title(f"{title1} vs {title2}", fontsize=11)
        ax.axis('off')
        h, w = img1.shape[1:]
        ax.axvline(x=w, color='white', linewidth=2)

    def visualize_attack_trajectory(self, x_clean: torch.Tensor, y_true: int,
                                    attack_name: str, eps: float, alpha: float, steps: int,
                                    save_path: Path = None):
        """åŠ¨æ€å±•ç¤ºæ”»å‡»è¿‡ç¨‹"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

        traj_probs = []
        traj_perturbs = []

        x_orig = x_clean.detach()
        x_adv = x_orig.clone()
        if attack_name == "pgd":
            x_adv = (x_orig + torch.empty_like(x_orig).uniform_(-eps, eps)).clamp(0, 1)

        for step in range(steps + 1):
            with torch.no_grad():
                logits = self.model(normalize_batch(x_adv, mean, std))
                probs = F.softmax(logits, dim=1)
                traj_probs.append(probs[0, [y_true, 805]].cpu().numpy())
                traj_perturbs.append(torch.norm(x_adv - x_orig).item())

            if step > 0 and attack_name == "pgd":
                x_adv = x_adv.detach().clone().requires_grad_(True)
                logits = self.model(normalize_batch(x_adv, mean, std))
                loss = F.cross_entropy(logits, torch.tensor([y_true], device=self.device))
                grad = torch.autograd.grad(loss, x_adv, only_inputs=True)[0]
                x_adv = x_adv + alpha * grad.sign()
                x_adv = torch.max(torch.min(x_adv, x_orig + eps), x_orig - eps).clamp(0, 1)
            elif attack_name == "fgsm" and step == 1:
                x_in = x_orig.clone().requires_grad_(True)
                logits = self.model(normalize_batch(x_in, mean, std))
                loss = F.cross_entropy(logits, torch.tensor([y_true], device=self.device))
                grad = torch.autograd.grad(loss, x_in, only_inputs=True)[0]
                x_adv = x_orig + eps * grad.sign()
                x_adv = x_adv.clamp(0, 1)
                break

        traj_probs = np.array(traj_probs)

        ax1.plot(traj_probs[:, 0], label='Original Class', color='green', linewidth=2, marker='o', markersize=3)
        ax1.plot(traj_probs[:, 1], label='Target Class', color='red', linewidth=2, marker='x', markersize=3)
        ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Decision Boundary')
        ax1.set_xlabel('Attack Step', fontsize=12)
        ax1.set_ylabel('Prediction Probability', fontsize=12)
        ax1.set_title(f'{attack_name.upper()} Attack Trajectory (Eps={eps:.5f})', fontsize=14)
        ax1.legend(loc='upper right')
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(-0.05, 1.05)

        ax2.plot(traj_perturbs, color='purple', linewidth=2, marker='s', markersize=3)
        ax2.set_xlabel('Attack Step', fontsize=12)
        ax2.set_ylabel('L2 Perturbation', fontsize=12)
        ax2.set_title('Perturbation Growth', fontsize=14)
        ax2.grid(True, alpha=0.3)

        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300)
        plt.show()
        print(f"  å·²ä¿å­˜: {save_path}")

    def visualize_perturbation_analysis(self, x_clean: torch.Tensor,
                                        results: Dict[str, Dict],
                                        save_path: Path = None):
        """æ‰°åŠ¨çš„é¢‘åŸŸå’Œç©ºåŸŸåˆ†æ"""
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle('Perturbation Spatial & Frequency Analysis', fontsize=16, fontweight='bold')

        for idx, (attack_name, result) in enumerate(results.items()):
            diff = (result["x_adv"] - x_clean).squeeze().cpu().numpy()
            axes[0, idx].hist(diff.flatten(), bins=50, alpha=0.7,
                              color=['red', 'blue', 'purple'][idx],
                              range=(-0.1, 0.1))
            axes[0, idx].set_title(f'{attack_name.upper()} Distribution', fontsize=12)
            axes[0, idx].set_xlabel('Perturbation Value')
            axes[0, idx].set_ylabel('Frequency')
            axes[0, idx].grid(True, alpha=0.3)

        for idx, (attack_name, result) in enumerate(results.items()):
            diff = (result["x_adv"] - x_clean).squeeze().cpu().numpy()
            fft_diff = np.fft.fft2(diff.transpose(1, 2, 0).mean(axis=2))
            fft_magnitude = np.abs(np.fft.fftshift(fft_diff))

            im = axes[1, idx].imshow(np.log1p(fft_magnitude), cmap='hot')
            axes[1, idx].set_title(f'{attack_name.upper()} Frequency', fontsize=12)
            axes[1, idx].axis('off')
            plt.colorbar(im, ax=axes[1, idx], fraction=0.046, pad=0.04)

        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300)
        plt.show()
        print(f"  å·²ä¿å­˜: {save_path}")

    def save_adv_images(self, results: Dict[str, Dict], output_dir: Path):
        """ä¿å­˜æ‰€æœ‰å¯¹æŠ—æ ·æœ¬å›¾åƒ"""
        output_dir.mkdir(parents=True, exist_ok=True)
        for attack_name, result in results.items():
            x_adv = self.denormalize(result["x_adv"])
            save_path = output_dir / f"adv_{attack_name}.png"
            save_image(x_adv, save_path)
            print(f"    {save_path}")


# ============= æ¨¡å‹å’Œæ•°æ®åŠ è½½ =============
def load_model(device: torch.device, model_name: str = "resnet50") -> torch.nn.Module:
    """âœ… åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆä¸ResNet.pyå®Œå…¨ä¸€è‡´ï¼‰"""
    print(f"Loading {model_name}...")

    # âœ… æ ¸å¿ƒä¿®å¤ï¼šä½¿ç”¨pretrained=Trueè€Œéweights=...ï¼Œç¡®ä¿åŠ è½½ç›¸åŒæƒé‡ç‰ˆæœ¬
    model = getattr(models, model_name)(pretrained=True).eval()

    return model.to(device)


def get_imagenet_transform() -> transforms.Compose:
    """ImageNetæ ‡å‡†åŒ–é¢„å¤„ç†"""
    return transform  # ä½¿ç”¨å…¨å±€å˜é‡


def get_device():
    """è·å–è®¡ç®—è®¾å¤‡"""
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")


# ============= ä¸»æ‰§è¡Œæµç¨‹ =============
def main():
    parser = argparse.ArgumentParser(
        description="å¯¹æŠ—æ”»å‡»å¯è§†åŒ–åˆ†æå™¨ v6.0 (æœ€ç»ˆæƒé‡ä¿®å¤ç‰ˆ)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="ç¤ºä¾‹:\n"
               "  python visualize_attacks.py --image picture/example.jpg\n"
               "  python visualize_attacks.py --image picture/example.jpg --eps 0.062745 --steps 40\n"
               "  python visualize_attacks.py --image picture/example.jpg --cw_c 0.1 --cw_steps 500"
    )

    # è¾“å…¥è®¾ç½®
    parser.add_argument("--image", type=str, required=True, help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--model", type=str, default="resnet50", choices=["resnet50", "vgg19"],
                        help="è¦æ”»å‡»çš„æ¨¡å‹")

    # æ”»å‡»å‚æ•°
    parser.add_argument("--eps", type=float, default=8 / 255, help="æ‰°åŠ¨ä¸Šé™ (default: 8/255)")
    parser.add_argument("--alpha", type=float, default=2 / 255, help="PGDæ­¥é•¿")
    parser.add_argument("--steps", type=int, default=20, help="PGDè¿­ä»£æ­¥æ•°")
    parser.add_argument("--cw_steps", type=int, default=100, help="CWæ”»å‡»æ­¥æ•°")
    parser.add_argument("--cw_c", type=float, default=1.0, help="CWæ”»å‡»cå‚æ•°")

    # è¾“å‡ºè®¾ç½®
    parser.add_argument("--output_dir", type=str, default="./attack_visualization",
                        help="è¾“å‡ºç›®å½•")
    parser.add_argument("--save_images", action="store_true", help="ä¿å­˜å¯¹æŠ—æ ·æœ¬å›¾ç‰‡")

    args = parser.parse_args()

    # è®¾å¤‡è®¾ç½®
    device = get_device()
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    if not torch.cuda.is_available():
        print("âš ï¸  è­¦å‘Š: æœªæ£€æµ‹åˆ°CUDAï¼ŒCPUæ¨¡å¼ä¼šéå¸¸æ…¢")

    # åŠ è½½æ¨¡å‹ï¼ˆâœ… ä½¿ç”¨ä¸ResNet.pyå®Œå…¨ç›¸åŒçš„æ–¹å¼ï¼‰
    model = load_model(device, args.model)

    # åŠ è½½å›¾åƒ
    image_path = Path(args.image)
    if not image_path.exists():
        raise FileNotFoundError(f"å›¾åƒä¸å­˜åœ¨: {image_path}")

    img = Image.open(image_path).convert("RGB")
    x_clean = transform(img).unsqueeze(0).to(device)

    # åˆå§‹åŒ–å¯è§†åŒ–å™¨ï¼ˆâœ… ä¸ä¼ mean/stdï¼Œä½¿ç”¨å…¨å±€å˜é‡ï¼‰
    visualizer = AttackVisualizer(model, device)

    # è·å–çœŸå®æ ‡ç­¾ï¼ˆç°åœ¨ä¸ResNet.pyå®Œå…¨ä¸€è‡´ï¼‰
    clean_pred_id, clean_pred_name, clean_prob = visualizer.predict(x_clean)
    print(f"\n{'=' * 60}")
    print(f"ğŸ–¼ï¸  è¾“å…¥å›¾åƒ: {image_path.name}")
    print(f"ğŸ¯ çœŸå®æ ‡ç­¾: {clean_pred_name} (class {clean_pred_id})")
    print(f"ğŸ“Š ç½®ä¿¡åº¦: {clean_prob:.4f}")  # å¿…é¡»æ˜¾ç¤º0.997
    print(f"{'=' * 60}")

    # æ‰§è¡Œä¸‰ç§æ”»å‡»ï¼ˆâœ… ä¼ é€’å…¨å±€CPUå¼ é‡ç»™æ”»å‡»å‡½æ•°ï¼‰
    print("\nâš”ï¸  æ­£åœ¨æ‰§è¡Œæ”»å‡»...")
    results = {}

    for attack_name in ["fgsm", "pgd", "cw"]:
        print(f"  æ‰§è¡Œ {attack_name.upper()}...")

        if attack_name == "fgsm":
            x_adv = fgsm_attack(model, x_clean, torch.tensor([clean_pred_id], device=device),
                                eps=args.eps, mean=mean, std=std)  # âœ… ä¼ é€’å…¨å±€CPUå¼ é‡
        elif attack_name == "pgd":
            x_adv = pgd_linf_attack(model, x_clean, torch.tensor([clean_pred_id], device=device),
                                    eps=args.eps, alpha=args.alpha, steps=args.steps,
                                    mean=mean, std=std)  # âœ… ä¼ é€’å…¨å±€CPUå¼ é‡
        else:  # cw
            cw_result = cw_l2_attack(model, x_clean, torch.tensor([clean_pred_id], device=device),
                                     mean=mean, std=std, c=args.cw_c, kappa=0.0,
                                     steps=args.cw_steps, lr=0.01)  # âœ… ä¼ é€’å…¨å±€CPUå¼ é‡
            x_adv = cw_result.x_adv

        # è·å–é¢„æµ‹ç»“æœï¼ˆä½¿ç”¨ä¿®å¤åçš„predictæ–¹æ³•ï¼‰
        adv_pred = visualizer.predict(x_adv)

        results[attack_name] = {
            "x_adv": x_adv,
            "pred_clean": (clean_pred_id, clean_pred_name, clean_prob),
            "pred_adv": adv_pred,
        }

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ============= ç”Ÿæˆå¯è§†åŒ– =============
    print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–...")

    # 1. æ”»å‡»æ•ˆæœå¯¹æ¯”å›¾
    visualizer.visualize_attack_grid(
        x_clean, results,
        save_path=output_dir / "attack_comparison.png"
    )

    # 2. æ”»å‡»è½¨è¿¹åˆ†æï¼ˆä»…PGDï¼‰
    print("  ç”Ÿæˆæ”»å‡»è½¨è¿¹å›¾...")
    visualizer.visualize_attack_trajectory(
        x_clean, clean_pred_id, "pgd",
        eps=args.eps, alpha=args.alpha, steps=args.steps,
        save_path=output_dir / "attack_trajectory.png"
    )

    # 3. æ‰°åŠ¨åˆ†æ
    print("  ç”Ÿæˆæ‰°åŠ¨åˆ†æå›¾...")
    visualizer.visualize_perturbation_analysis(
        x_clean, results,
        save_path=output_dir / "perturbation_analysis.png"
    )

    # 4. å®šé‡æŒ‡æ ‡æŠ¥å‘Š
    print("\nğŸ“ˆ å®šé‡è¯„ä¼°æŒ‡æ ‡:")
    print("-" * 80)
    for attack_name, result in results.items():
        clean_info = result["pred_clean"]
        adv_info = result["pred_adv"]

        # åˆ¤æ–­æ”»å‡»æ˜¯å¦æˆåŠŸ
        success = "SUCCESS" if clean_info[0] != adv_info[0] else "FAILED"
        print(f"\n{attack_name.upper()}æ”»å‡» [{success}]:")
        print(f"  é¢„æµ‹å˜åŒ–: {clean_info[1]} ({clean_info[2]:.4f}) â†’ "
              f"{adv_info[1]} ({adv_info[2]:.4f})")

        metrics = visualizer.calculate_metrics(x_clean, result["x_adv"])
        for metric, value in metrics.items():
            if isinstance(value, float):
                if "SSIM" in metric or "PSNR" in metric:
                    print(f"  {metric:.<25} {value:.4f}")
                else:
                    print(f"  {metric:.<25} {value:.6f}")
            else:
                print(f"  {metric:.<25} {value}")

    # 5. ä¿å­˜å¯¹æŠ—æ ·æœ¬å›¾åƒ
    if args.save_images:
        print("\nğŸ’¾ ä¿å­˜å¯¹æŠ—æ ·æœ¬...")
        visualizer.save_adv_images(results, output_dir / "adversarial_images")

    # 6. ç”ŸæˆJSONæŠ¥å‘Š
    report = {
        "image": str(image_path.absolute()),
        "model": args.model,
        "clean_prediction": {
            "class_id": int(clean_pred_id),
            "class_name": clean_pred_name,
            "confidence": float(clean_prob)
        },
        "params": {
            "eps": float(args.eps),
            "alpha": float(args.alpha),
            "steps": int(args.steps),
            "cw_c": float(args.cw_c),
            "cw_steps": int(args.cw_steps)
        },
        "attacks": {
            name: {
                "predicted_class": int(result["pred_adj"][0]),
                "predicted_name": result["pred_adv"][1],
                "confidence": float(result["pred_adv"][2]),
                "success": result["pred_clean"][0] != result["pred_adv"][0],
                "metrics": visualizer.calculate_metrics(x_clean, result["x_adv"]),
            }
            for name, result in results.items()
        }
    }

    # ä¿å­˜æŠ¥å‘Šæ—¶å¤„ç†numpyæ•°æ®ç±»å‹
    def json_serializable(obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.float32):
            return float(obj)
        elif isinstance(obj, torch.Tensor):
            return obj.cpu().numpy().tolist()
        return obj

    with open(output_dir / "attack_report.json", "w", encoding='utf-8') as f:
        json.dump(report, f, indent=2, default=json_serializable, ensure_ascii=False)

    print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    print(f"ğŸ“„ JSONæŠ¥å‘Š: {output_dir / 'attack_report.json'}")
    print(f"\nğŸ‰ å®Œæˆï¼è¯·æ£€æŸ¥è¾“å‡ºç›®å½•ä¸­çš„PNGå›¾ç‰‡ã€‚")


# ============= å…¥å£ & ä¾èµ–æ£€æŸ¥ =============
if __name__ == "__main__":
    # æ£€æŸ¥å…³é”®ä¾èµ–
    try:
        import torchmetrics
    except ImportError:
        print("âŒ é”™è¯¯: torchmetricsæœªå®‰è£…")
        print("   è¯·è¿è¡Œ: pip install torchmetrics")
        exit(1)

    try:
        import matplotlib
    except ImportError:
        print("âŒ é”™è¯¯: matplotlibæœªå®‰è£…")
        print("   è¯·è¿è¡Œ: pip install matplotlib")
        exit(1)

    main()