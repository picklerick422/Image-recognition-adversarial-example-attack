#!/usr/bin/env python3
"""
å¯¹æŠ—æ”»å‡»å¯è§†åŒ–åˆ†æå™¨
æ”¯æŒ FGSM / PGD / CW-L2 æ”»å‡»æ–¹æ³•çš„å…¨é¢è¯„ä¼°
"""
from __future__ import annotations
import argparse
import json
from pathlib import Path
from typing import Dict, Tuple

import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn.functional as F
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
from torchvision.utils import save_image


from dataclasses import dataclass
from typing import Optional
# ==================== ä½ çš„æ”»å‡»ä»£ç ï¼ˆä¿æŒä¸å˜ï¼‰ ====================



def normalize_batch(x: torch.Tensor, mean: torch.Tensor, std: torch.Tensor) -> torch.Tensor:
    if mean.ndim != 1 or std.ndim != 1:
        raise ValueError("mean/std must be 1D tensors with shape [C]")
    if x.ndim != 4:
        raise ValueError("x must be a 4D tensor with shape [N, C, H, W]")
    mean = mean.to(device=x.device, dtype=x.dtype).view(1, -1, 1, 1)
    std = std.to(device=x.device, dtype=x.dtype).view(1, -1, 1, 1)
    return (x - mean) / std


def fgsm_attack(
        model: torch.nn.Module,
        x: torch.Tensor,
        y_true: torch.Tensor,
        *,
        eps: float,
        mean: torch.Tensor,
        std: torch.Tensor,
) -> torch.Tensor:
    x_in = x.detach().clone().requires_grad_(True)
    logits = model(normalize_batch(x_in, mean, std))
    loss = F.cross_entropy(logits, y_true)
    grad = torch.autograd.grad(loss, x_in, only_inputs=True)[0]
    x_adv = x_in + eps * grad.sign()
    return x_adv.clamp(0.0, 1.0).detach()


def pgd_linf_attack(
        model: torch.nn.Module,
        x: torch.Tensor,
        y_true: torch.Tensor,
        *,
        eps: float,
        alpha: float,
        steps: int,
        mean: torch.Tensor,
        std: torch.Tensor,
        random_start: bool = True,
) -> torch.Tensor:
    x_orig = x.detach()
    if random_start:
        x_adv = (x_orig + torch.empty_like(x_orig).uniform_(-eps, eps)).clamp(0.0, 1.0)
    else:
        x_adv = x_orig.clone()

    for _ in range(int(steps)):
        x_adv = x_adv.detach().clone().requires_grad_(True)
        logits = model(normalize_batch(x_adv, mean, std))
        loss = F.cross_entropy(logits, y_true)
        grad = torch.autograd.grad(loss, x_adv, only_inputs=True)[0]

        x_adv = x_adv + alpha * grad.sign()
        x_adv = torch.max(torch.min(x_adv, x_orig + eps), x_orig - eps)
        x_adv = x_adv.clamp(0.0, 1.0)

    return x_adv.detach()


def _atanh(x: torch.Tensor) -> torch.Tensor:
    return 0.5 * (torch.log1p(x) - torch.log1p(-x))


@dataclass(frozen=True)
class CWResult:
    x_adv: torch.Tensor
    success: torch.Tensor


def cw_l2_attack(
        model: torch.nn.Module,
        x: torch.Tensor,
        y_true: torch.Tensor,
        *,
        mean: torch.Tensor,
        std: torch.Tensor,
        c: float = 1.0,
        kappa: float = 0.0,
        steps: int = 1000,
        lr: float = 1e-2,
        targeted: bool = False,
        y_target: Optional[torch.Tensor] = None,
) -> CWResult:
    if targeted and y_target is None:
        raise ValueError("y_target must be provided when targeted=True")

    x0 = x.detach().clamp(0.0, 1.0)
    eps = 1e-6
    x0_tanh = x0 * (1.0 - 2.0 * eps) + eps
    w0 = _atanh(x0_tanh * 2.0 - 1.0).detach()
    w = w0.clone().requires_grad_(True)

    optimizer = torch.optim.Adam([w], lr=lr)

    best_adv = x0.clone()
    best_l2 = torch.full((x0.shape[0],), float("inf"), device=x0.device, dtype=x0.dtype)
    best_success = torch.zeros((x0.shape[0],), device=x0.device, dtype=torch.bool)

    y_cmp = y_target if targeted else y_true

    for _ in range(int(steps)):
        x_adv = 0.5 * (torch.tanh(w) + 1.0)
        logits = model(normalize_batch(x_adv, mean, std))

        num_classes = logits.shape[1]
        y_onehot = F.one_hot(y_cmp, num_classes=num_classes).to(dtype=logits.dtype)

        real = (logits * y_onehot).sum(dim=1)
        other = (logits - 1e4 * y_onehot).amax(dim=1)

        if targeted:
            f = torch.clamp(other - real + kappa, min=0.0)
            success = (logits.argmax(dim=1) == y_cmp)
        else:
            f = torch.clamp(real - other + kappa, min=0.0)
            success = (logits.argmax(dim=1) != y_cmp)

        l2 = (x_adv - x0).view(x0.shape[0], -1).pow(2).sum(dim=1)
        loss = (l2 + c * f).sum()

        optimizer.zero_grad(set_to_none=True)
        loss.backward()
        optimizer.step()

        improved = success & (l2 < best_l2)
        if improved.any():
            best_l2 = torch.where(improved, l2, best_l2)
            best_success = best_success | improved
            best_adv = torch.where(improved.view(-1, 1, 1, 1), x_adv.detach(), best_adv)

    final_adv = torch.where(best_success.view(-1, 1, 1, 1), best_adv, (0.5 * (torch.tanh(w) + 1.0)).detach())
    return CWResult(x_adv=final_adv, success=best_success)


# ==================== å¯è§†åŒ–æ ¸å¿ƒç±» ====================
class AttackVisualizer:
    def __init__(self, model: torch.nn.Module, device: torch.device,
                 mean: torch.Tensor, std: torch.Tensor,
                 imagenet_classes: list = None):
        self.model = model
        self.device = device
        self.mean = mean
        self.std = std
        self.imagenet_classes = imagenet_classes or self._load_imagenet_classes()

    def _load_imagenet_classes(self) -> list:
        """åŠ è½½ImageNetç±»åˆ«æ ‡ç­¾"""
        import requests
        url = "https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
        try:
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                return response.text.strip().split('\n')
        except:
            pass
        # å¤‡ç”¨ï¼šç”Ÿæˆé€šç”¨æ ‡ç­¾
        return [f"class_{i}" for i in range(1000)]

    def denormalize(self, x: torch.Tensor) -> torch.Tensor:
        """åå½’ä¸€åŒ–åˆ°[0,1]"""
        mean = self.mean.view(1, 3, 1, 1)
        std = self.std.view(1, 3, 1, 1)
        return torch.clamp(x * std + mean, 0.0, 1.0)

    def predict(self, x: torch.Tensor) -> Tuple[int, str, float]:
        """é¢„æµ‹å¹¶è¿”å›(ç±»åˆ«ID, åç§°, ç½®ä¿¡åº¦)"""
        with torch.no_grad():
            logits = self.model(normalize_batch(x, self.mean, self.std))
            probs = F.softmax(logits, dim=1)
            pred_id = probs.argmax(dim=1).item()
            confidence = probs[0, pred_id].item()
            class_name = self.imagenet_classes[pred_id]
        return pred_id, class_name, confidence

    def calculate_metrics(self, x_clean: torch.Tensor, x_adv: torch.Tensor) -> Dict:
        """è®¡ç®—æ”»å‡»çš„å®šé‡æŒ‡æ ‡"""
        diff = x_adv - x_clean

        # LpèŒƒæ•°
        l_inf = torch.max(torch.abs(diff)).item()
        l_2 = torch.norm(diff, p=2).item()
        l_1 = torch.norm(diff, p=1).item()

        # è§†è§‰ç›¸ä¼¼åº¦
        x_clean_np = x_clean.cpu().numpy()
        x_adv_np = x_adv.cpu().numpy()

        # SSIM (ç»“æ„ç›¸ä¼¼æ€§)
        try:
            from skimage.metrics import structural_similarity as ssim
            ssim_score = ssim(
                x_clean_np[0].transpose(1, 2, 0),
                x_adv_np[0].transpose(1, 2, 0),
                multichannel=True,
                data_range=1.0
            )
        except ImportError:
            ssim_score = 0.0

        # PSNR (å³°å€¼ä¿¡å™ªæ¯”)
        mse = torch.mean(diff ** 2).item()
        psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')

        # é«˜é¢‘æ‰°åŠ¨æ¯”ä¾‹
        fft_diff = torch.fft.fft2(diff)
        high_freq_ratio = (torch.abs(fft_diff) > 0.1).float().mean().item()

        # æ‰°åŠ¨åƒç´ æ¯”ä¾‹
        perturbed_pixels = (torch.abs(diff) > 1 / 255).float().mean().item()

        return {
            "Lâˆ (pixel)": l_inf,
            "L2": l_2,
            "L1": l_1,
            "SSIM": ssim_score,
            "PSNR": psnr,
            "Perturbed Pixels %": perturbed_pixels * 100,
            "High Freq Ratio": high_freq_ratio * 100,
        }

    def visualize_attack_grid(self, x_clean: torch.Tensor,
                              results: Dict[str, Dict],
                              save_path: Path = None):
        """
        ç”Ÿæˆæ”»å‡»æ•ˆæœå›¾ç½‘æ ¼ï¼šåŸå›¾ + å¯¹æŠ—æ ·æœ¬ + æ‰°åŠ¨æ”¾å¤§
        """
        n_attacks = len(results)
        fig = plt.figure(figsize=(4 * 3, 4 * n_attacks))

        # å‡†å¤‡æ•°æ®
        x_clean_denorm = self.denormalize(x_clean).squeeze()

        for idx, (attack_name, result) in enumerate(results.items()):
            x_adv = result["x_adv"]
            x_adv_denorm = self.denormalize(x_adv).squeeze()
            diff = (x_adv - x_clean).squeeze()

            # Row 1: åŸå›¾ vs å¯¹æŠ—æ ·æœ¬
            ax1 = plt.subplot(n_attacks, 3, idx * 3 + 1)
            self._plot_image_pair(ax1, x_clean_denorm, x_adv_denorm,
                                  "Original", "Adversarial")

            # Row 2: æ‰°åŠ¨å›¾ Ã—10
            ax2 = plt.subplot(n_attacks, 3, idx * 3 + 2)
            diff_10x = torch.clamp(x_clean_denorm + 10 * diff, 0, 1)
            self._plot_image(ax2, diff_10x, "Perturbation Ã—10")

            # Row 3: æ‰°åŠ¨å›¾ Ã—50
            ax3 = plt.subplot(n_attacks, 3, idx * 3 + 3)
            diff_50x = torch.clamp(x_clean_denorm + 50 * diff, 0, 1)
            self._plot_image(ax3, diff_50x, "Perturbation Ã—50")

            # æ·»åŠ æ”»å‡»ä¿¡æ¯
            pred_clean = result["pred_clean"]
            pred_adv = result["pred_adv"]
            success = "âœ… SUCCESS" if pred_clean[0] != pred_adv[0] else "âŒ FAILED"
            fig.text(0.5, 1 - (idx * (1 / n_attacks) - 0.02),
                     f"{attack_name.upper()} Attack - {success}",
                     ha='center', va='top', fontsize=14, fontweight='bold')

        plt.tight_layout(rect=[0, 0, 1, 0.98])
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_image(self, ax, img_tensor, title):
        """ç»˜åˆ¶å•å¼ å›¾åƒ"""
        img_np = img_tensor.permute(1, 2, 0).cpu().numpy()
        ax.imshow(img_np)
        ax.set_title(title, fontsize=11)
        ax.axis('off')

    def _plot_image_pair(self, ax, img1, img2, title1, title2):
        """ç»˜åˆ¶å¯¹æ¯”å›¾åƒ"""
        img_np = torch.cat([img1, img2], dim=2).permute(1, 2, 0).cpu().numpy()
        ax.imshow(img_np)
        ax.set_title(f"{title1} vs {title2}", fontsize=11)
        ax.axis('off')
        # æ·»åŠ åˆ†å‰²çº¿
        h, w = img1.shape[1:]
        ax.axvline(x=w, color='white', linewidth=2)

    def visualize_attack_trajectory(self, x_clean: torch.Tensor, y_true: int,
                                    attack_name: str, eps: float, alpha: float, steps: int,
                                    save_path: Path = None):
        """
        åŠ¨æ€å±•ç¤ºæ”»å‡»è¿‡ç¨‹ï¼šç½®ä¿¡åº¦å˜åŒ–å’Œæ‰°åŠ¨å¢é•¿
        """
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

        # å­˜å‚¨è½¨è¿¹æ•°æ®
        traj_probs = []
        traj_perturbs = []

        # æ‰§è¡Œæ”»å‡»å¹¶è®°å½•ä¸­é—´ç»“æœ
        x_orig = x_clean.detach()
        x_adv = x_orig.clone()
        if attack_name == "pgd":
            x_adv = (x_orig + torch.empty_like(x_orig).uniform_(-eps, eps)).clamp(0, 1)

        for step in range(steps + 1):
            if step > 0:
                if attack_name == "pgd":
                    # PGDå•æ­¥
                    x_adv = x_adv.detach().clone().requires_grad_(True)
                    logits = self.model(normalize_batch(x_adv, self.mean, self.std))
                    loss = F.cross_entropy(logits, torch.tensor([y_true], device=self.device))
                    grad = torch.autograd.grad(loss, x_adv, only_inputs=True)[0]
                    x_adv = x_adv + alpha * grad.sign()
                    x_adv = torch.max(torch.min(x_adv, x_orig + eps), x_orig - eps).clamp(0, 1)
                elif attack_name == "fgsm":
                    # FGSMä¸€æ¬¡æ€§
                    if step == 1:
                        x_in = x_orig.clone().requires_grad_(True)
                        logits = self.model(normalize_batch(x_in, self.mean, self.std))
                        loss = F.cross_entropy(logits, torch.tensor([y_true], device=self.device))
                        grad = torch.autograd.grad(loss, x_in, only_inputs=True)[0]
                        x_adv = x_orig + eps * grad.sign()
                        x_adv = x_adv.clamp(0, 1)
                    break

            # è®°å½•å½“å‰çŠ¶æ€
            with torch.no_grad():
                logits = self.model(normalize_batch(x_adv, self.mean, self.std))
                probs = F.softmax(logits, dim=1)
                traj_probs.append(probs[0, [y_true, 805]].cpu().numpy())  # ç†ŠçŒ«å’Œè¶³çƒ
                traj_perturbs.append(torch.norm(x_adv - x_orig).item())

        traj_probs = np.array(traj_probs)

        # ç»˜åˆ¶æ¦‚ç‡è½¨è¿¹
        ax1.plot(traj_probs[:, 0], label='Original Class (Panda)', color='green', linewidth=2, marker='o', markersize=3)
        ax1.plot(traj_probs[:, 1], label='Target Class (Soccer)', color='red', linewidth=2, marker='x', markersize=3)
        ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Decision Boundary')
        ax1.set_xlabel('Attack Step', fontsize=12)
        ax1.set_ylabel('Prediction Probability', fontsize=12)
        ax1.set_title(f'{attack_name.upper()} Attack Trajectory (Eps={eps:.3f})', fontsize=14)
        ax1.legend(loc='upper right')
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim(-0.05, 1.05)

        # ç»˜åˆ¶æ‰°åŠ¨å¢é•¿
        ax2.plot(traj_perturbs, color='purple', linewidth=2, marker='s', markersize=3)
        ax2.set_xlabel('Attack Step', fontsize=12)
        ax2.set_ylabel('L2 Perturbation', fontsize=12)
        ax2.set_title('Perturbation Growth', fontsize=14)
        ax2.grid(True, alpha=0.3)

        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300)
        plt.show()

    def visualize_perturbation_analysis(self, x_clean: torch.Tensor,
                                        results: Dict[str, Dict],
                                        save_path: Path = None):
        """
        æ‰°åŠ¨çš„é¢‘åŸŸå’Œç©ºåŸŸåˆ†æ
        """
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle('Perturbation Spatial & Frequency Analysis', fontsize=16, fontweight='bold')

        # 1. ç©ºåŸŸåˆ†å¸ƒç›´æ–¹å›¾
        for idx, (attack_name, result) in enumerate(results.items()):
            diff = (result["x_adv"] - x_clean).squeeze().cpu().numpy()
            axes[0, idx].hist(diff.flatten(), bins=50, alpha=0.7, color=['red', 'blue', 'purple'][idx])
            axes[0, idx].set_title(f'{attack_name.upper()} Perturbation Distribution', fontsize=12)
            axes[0, idx].set_xlabel('Perturbation Value')
            axes[0, idx].set_ylabel('Frequency')
            axes[0, idx].grid(True, alpha=0.3)

        # 2. é¢‘åŸŸåˆ†æ
        for idx, (attack_name, result) in enumerate(results.items()):
            diff = (result["x_adv"] - x_clean).squeeze().cpu().numpy()
            fft_diff = np.fft.fft2(diff.transpose(1, 2, 0).mean(axis=2))
            fft_magnitude = np.abs(np.fft.fftshift(fft_diff))

            im = axes[1, idx].imshow(np.log1p(fft_magnitude), cmap='hot')
            axes[1, idx].set_title(f'{attack_name.upper()} Frequency Spectrum', fontsize=12)
            axes[1, idx].axis('off')
            plt.colorbar(im, ax=axes[1, idx], fraction=0.046, pad=0.04)

        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300)
        plt.show()

    def save_adv_images(self, results: Dict[str, Dict], output_dir: Path):
        """ä¿å­˜æ‰€æœ‰å¯¹æŠ—æ ·æœ¬å›¾åƒ"""
        output_dir.mkdir(parents=True, exist_ok=True)
        for attack_name, result in results.items():
            x_adv = self.denormalize(result["x_adv"])
            save_path = output_dir / f"adv_{attack_name}.png"
            save_image(x_adv, save_path)
            print(f"  Saved: {save_path}")


# ==================== ä¸»æ‰§è¡Œæµç¨‹ ====================
def load_model(device: torch.device, model_name: str = "resnet50") -> torch.nn.Module:
    """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
    print(f"Loading {model_name}...")
    try:
        if model_name == "resnet50":
            model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
        elif model_name == "vgg19":
            model = models.vgg19(weights=models.VGG19_Weights.DEFAULT)
        else:
            raise ValueError(f"Unsupported model: {model_name}")
    except:
        # å›é€€åˆ°æ—§ç‰ˆAPI
        model = getattr(models, model_name)(pretrained=True)

    return model.eval().to(device)


def get_imagenet_transform() -> transforms.Compose:
    """ImageNetæ ‡å‡†åŒ–é¢„å¤„ç†"""
    return transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
    ])


def get_mean_std(device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:
    """ImageNetå‡å€¼æ–¹å·®"""
    mean = torch.tensor([0.485, 0.456, 0.406], device=device)
    std = torch.tensor([0.229, 0.224, 0.225], device=device)
    return mean, std


def main():
    parser = argparse.ArgumentParser(description="å¯¹æŠ—æ”»å‡»å¯è§†åŒ–åˆ†æå™¨")

    # è¾“å…¥è®¾ç½®
    parser.add_argument("--image", type=str, required=True, help="è¾“å…¥å›¾åƒè·¯å¾„")
    parser.add_argument("--model", type=str, default="resnet50", choices=["resnet50", "vgg19"],
                        help="è¦æ”»å‡»çš„æ¨¡å‹")

    # æ”»å‡»å‚æ•°
    parser.add_argument("--eps", type=float, default=8 / 255, help="æ‰°åŠ¨ä¸Šé™ (default: 8/255)")
    parser.add_argument("--alpha", type=float, default=2 / 255, help="PGDæ­¥é•¿")
    parser.add_argument("--steps", type=int, default=20, help="PGDè¿­ä»£æ­¥æ•°")
    parser.add_argument("--cw_steps", type=int, default=100, help="CWæ”»å‡»æ­¥æ•°")
    parser.add_argument("--cw_c", type=float, default=1.0, help="CWæ”»å‡»cå‚æ•°")

    # è¾“å‡ºè®¾ç½®
    parser.add_argument("--output_dir", type=str, default="./attack_visualization",
                        help="è¾“å‡ºç›®å½•")
    parser.add_argument("--save_images", action="store_true", help="ä¿å­˜å¯¹æŠ—æ ·æœ¬å›¾ç‰‡")

    args = parser.parse_args()

    # è®¾å¤‡è®¾ç½®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # åŠ è½½æ¨¡å‹å’Œå›¾åƒ
    model = load_model(device, args.model)
    transform = get_imagenet_transform()

    image_path = Path(args.image)
    if not image_path.exists():
        raise FileNotFoundError(f"å›¾åƒä¸å­˜åœ¨: {image_path}")

    img = Image.open(image_path).convert("RGB")
    x_clean = transform(img).unsqueeze(0).to(device)

    # è·å–å‡å€¼æ–¹å·®
    mean, std = get_mean_std(device)

    # åˆå§‹åŒ–å¯è§†åŒ–å™¨
    visualizer = AttackVisualizer(model, device, mean, std)

    # è·å–çœŸå®æ ‡ç­¾ï¼ˆä½¿ç”¨æ¨¡å‹é¢„æµ‹ä½œä¸ºä¼ªæ ‡ç­¾ï¼‰
    clean_pred_id, clean_pred_name, clean_prob = visualizer.predict(x_clean)
    print(f"\n{'=' * 60}")
    print(f"ğŸ–¼ï¸  è¾“å…¥å›¾åƒ: {image_path.name}")
    print(f"ğŸ¯ çœŸå®æ ‡ç­¾: {clean_pred_name} (class {clean_pred_id})")
    print(f"ğŸ“Š ç½®ä¿¡åº¦: {clean_prob:.4f}")
    print(f"{'=' * 60}")

    # æ‰§è¡Œä¸‰ç§æ”»å‡»
    print("\nâš”ï¸  æ­£åœ¨æ‰§è¡Œæ”»å‡»...")
    results = {}

    # 1. FGSMæ”»å‡»
    print("  æ‰§è¡Œ FGSM...")
    x_fgsm = fgsm_attack(model, x_clean, torch.tensor([clean_pred_id], device=device),
                         eps=args.eps, mean=mean, std=std)
    fgsm_pred = visualizer.predict(x_fgsm)
    results["fgsm"] = {
        "x_adv": x_fgsm,
        "pred_clean": (clean_pred_id, clean_pred_name, clean_prob),
        "pred_adv": fgsm_pred,
    }

    # 2. PGDæ”»å‡»
    print("  æ‰§è¡Œ PGD...")
    x_pgd = pgd_linf_attack(model, x_clean, torch.tensor([clean_pred_id], device=device),
                            eps=args.eps, alpha=args.alpha, steps=args.steps,
                            mean=mean, std=std)
    pgd_pred = visualizer.predict(x_pgd)
    results["pgd"] = {
        "x_adv": x_pgd,
        "pred_clean": (clean_pred_id, clean_pred_name, clean_prob),
        "pred_adv": pgd_pred,
    }

    # 3. CW-L2æ”»å‡»
    print("  æ‰§è¡Œ CW-L2...")
    cw_result = cw_l2_attack(model, x_clean, torch.tensor([clean_pred_id], device=device),
                             mean=mean, std=std, c=args.cw_c, kappa=0.0,
                             steps=args.cw_steps, lr=0.01)
    x_cw = cw_result.x_adv
    cw_pred = visualizer.predict(x_cw)
    results["cw"] = {
        "x_adv": x_cw,
        "pred_clean": (clean_pred_id, clean_pred_name, clean_prob),
        "pred_adv": cw_pred,
        "success": cw_result.success.item(),
    }

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ==================== ç”Ÿæˆå¯è§†åŒ– ====================
    print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–...")

    # 1. æ”»å‡»æ•ˆæœç½‘æ ¼å›¾
    print("  ç”Ÿæˆæ”»å‡»æ•ˆæœå¯¹æ¯”å›¾...")
    visualizer.visualize_attack_grid(
        x_clean, results,
        save_path=output_dir / "attack_comparison.png"
    )

    # 2. æ”»å‡»è½¨è¿¹åˆ†æï¼ˆä»…PGDï¼‰
    print("  ç”Ÿæˆæ”»å‡»è½¨è¿¹å›¾...")
    visualizer.visualize_attack_trajectory(
        x_clean, clean_pred_id, "pgd",
        eps=args.eps, alpha=args.alpha, steps=args.steps,
        save_path=output_dir / "attack_trajectory.png"
    )

    # 3. æ‰°åŠ¨åˆ†æ
    print("  ç”Ÿæˆæ‰°åŠ¨åˆ†æå›¾...")
    visualizer.visualize_perturbation_analysis(
        x_clean, results,
        save_path=output_dir / "perturbation_analysis.png"
    )

    # 4. å®šé‡æŒ‡æ ‡æŠ¥å‘Š
    print("\nğŸ“ˆ å®šé‡è¯„ä¼°æŒ‡æ ‡:")
    print("-" * 80)
    for attack_name, result in results.items():
        print(f"\n{attack_name.upper()}æ”»å‡»:")
        print(f"  é¢„æµ‹å˜åŒ–: {result['pred_clean'][1]} ({result['pred_clean'][2]:.4f}) â†’ "
              f"{result['pred_adv'][1]} ({result['pred_adv'][2]:.4f})")

        metrics = visualizer.calculate_metrics(x_clean, result["x_adv"])
        for metric, value in metrics.items():
            if "SSIM" in metric or "PSNR" in metric:
                print(f"  {metric}: {value:.4f}")
            else:
                print(f"  {metric}: {value:.6f}")

    # 5. ä¿å­˜å¯¹æŠ—æ ·æœ¬å›¾åƒ
    if args.save_images:
        print("\nğŸ’¾ ä¿å­˜å¯¹æŠ—æ ·æœ¬...")
        visualizer.save_adv_images(results, output_dir / "adversarial_images")

    # 6. ç”ŸæˆJSONæŠ¥å‘Š
    report = {
        "image": str(image_path),
        "model": args.model,
        "clean_prediction": {
            "class_id": int(clean_pred_id),
            "class_name": clean_pred_name,
            "confidence": float(clean_prob)
        },
        "attacks": {
            name: {
                "predicted_class": int(result["pred_adv"][0]),
                "predicted_name": result["pred_adv"][1],
                "confidence": float(result["pred_adv"][2]),
                "success": result["pred_clean"][0] != result["pred_adv"][0],
                "metrics": visualizer.calculate_metrics(x_clean, result["x_adv"]),
            }
            for name, result in results.items()
        }
    }

    with open(output_dir / "attack_report.json", "w") as f:
        json.dump(report, f, indent=2, default=str)

    print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    print(f"ğŸ“„ JSONæŠ¥å‘Š: {output_dir / 'attack_report.json'}")


if __name__ == "__main__":
    main()