# 对抗样本攻击与防御实验 - 技术实施要点拆解
##### 原文
（对抗攻击）人工智能的图像识别技术被广泛应用，请同学们自行实现或寻找一个图像识别类的算法（比如通过图片识别出动物），并对其进行对抗样本攻击，使其识别产生错误，具体要求如下：
- 实现至少三种对抗样本攻击方法（FGSM、PGD、CW、AutoAttack等），越多越好。分析比较不同方法的攻击效果，讨论哪种攻击更隐蔽更难以察觉，提供可视化输出和攻击过程分析。
- 实现至少两种对于对抗样本攻击的防御手段，如输入预处理、简易检测器设计、对抗训练等。并测试不同防御手段对于不同的攻击方法的防御效果，比较不同攻击方法和攻击强度下的对抗攻击成功率。
- 针对黑盒模型，开展迁移攻击（Transferability Attack），比如说，在ResNet50上产生攻击样本，对VGG19展开攻击，使用不同的模型架构，比如卷积神经网络和Vision Transformer等，详细讨论攻击的黑盒迁移性与模型架构间的关系。

## 一、基础技术准备：目标模型与数据集搭建

### 1. 图像识别模型选型与部署

- 核心动作：选定1个基础模型（用于攻击/防御基础实验）+ 2种不同架构模型（用于迁移攻击）

    - 可选模型：CNN类（ResNet50、VGG19、AlexNet）、Vision Transformer（ViT-B/16、ViT-L/14）

    - 技术要点：使用预训练权重（基于ImageNet/CIFAR-10），或轻量化微调；封装模型推理接口（输入图像→输出类别概率）

- 技术要求：确保模型可获取梯度（白盒攻击场景），黑盒场景仅暴露输入输出接口

### 2. 数据集选取与预处理

- 核心动作：筛选图像识别数据集（需覆盖清晰类别，便于攻击效果验证）

    - 可选数据集：CIFAR-10（10类、32×32）、ImageNet子集（1000类、224×224）、自定义动物/物体数据集

- 技术预处理：

    - 图像标准化（如归一化到[0,1]或[-1,1]，匹配模型输入要求）

    - 数据划分：训练集（用于对抗训练防御）、测试集（用于攻击/防御效果验证，≥100张有效图像）

    - 格式转换：统一为张量格式（适配PyTorch/TensorFlow框架）

## 二、对抗样本攻击技术实现

### 1. 核心攻击算法技术落地（≥3种）

#### （1）FGSM（快速梯度符号法）

- 技术原理：利用损失函数对输入图像的梯度符号，添加单步扰动

- 关键技术步骤：

    1. 计算目标图像在模型上的分类损失对像素的梯度（∇ₓJ(θ,x,y)）

    2. 取梯度符号（sign），乘以扰动步长ε（控制攻击强度）

    3. 对原始图像添加扰动，并裁剪至合法像素范围（如[0,1]）

- 技术要点：ε值调试（0.01~0.1），梯度计算需开启自动求导，避免梯度累积

#### （2）PGD（投影梯度下降）

- 技术原理：多步迭代添加扰动，每步扰动后投影到原始图像的ε邻域内，提升攻击成功率

- 关键技术步骤：

    1. 初始化对抗样本（可在原始图像ε邻域内随机扰动）

    2. 迭代T步：每步计算当前样本的梯度→添加小步扰动（α<ε）→投影回ε邻域（确保扰动不超标）

    3. 最终裁剪至合法像素范围

- 技术要点：迭代次数T（10~100）、步长α与ε的匹配（如α=ε/10），避免梯度消失

#### （3）CW攻击（Carlini-Wagner）

- 技术原理：通过优化目标函数（最小化扰动+最大化分类错误概率）生成对抗样本，隐蔽性更强

- 关键技术步骤：

    1. 引入变量t（替代原始图像x），通过sigmoid函数映射到[0,1]，简化约束

    2. 构造目标函数：L₂扰动损失 + 分类错误惩罚项（使用置信度阈值）

    3. 用Adam优化器最小化目标函数，迭代生成对抗样本

- 技术要点：置信度参数c调试、优化器学习率（1e-31e-2）、迭代次数（1001000）

#### （4）可选扩展攻击（AutoAttack/BIM等）

- AutoAttack：集成多种基础攻击（FGSM、PGD、CW变体），自适应调整攻击参数，提升鲁棒性

- BIM（基本迭代法）：FGSM的迭代版本，每步添加小扰动，增强攻击效果

### 2. 攻击效果技术评估

- 量化指标计算：

    - 攻击成功率 = 对抗样本被模型误分类的数量 / 测试集总数量

    - 扰动隐蔽性：PSNR（峰值信噪比，越高越隐蔽）、SSIM（结构相似性，越接近1越隐蔽）

    - 计算效率：单张图像生成对抗样本的平均耗时（CPU/GPU环境下分别统计）

- 可视化技术实现：

    - 原始图像与对抗样本的像素级对比（放大差异区域）

    - 梯度热力图（展示模型对图像像素的敏感区域）

    - 不同ε值下攻击成功率与隐蔽性的权衡曲线

## 三、对抗防御技术实现

### 1. 核心防御算法技术落地（≥2种）

#### （1）输入预处理防御

- 技术原理：通过对输入图像进行降噪/平滑处理，消除对抗扰动

- 可选方案及技术实现：

    - 高斯滤波：使用5×5/3×3卷积核，σ值（0.5~2.0）调试，过滤高频扰动

    - 中值滤波：3×3窗口，抑制椒盐噪声类对抗扰动

    - 对抗样本去噪（ADV-DeNoise）：基于自编码器训练，输入对抗样本→输出去噪后的正常图像

- 技术要点：预处理后需保持图像语义不变（不影响模型正常分类准确率）

#### （2）对抗训练防御

- 技术原理：将对抗样本融入训练集，让模型学习对抗扰动特征，提升鲁棒性

- 关键技术步骤：

    1. 生成训练集对应的对抗样本（使用FGSM/PGD攻击当前模型）

    2. 构建混合训练集：原始样本（标签y）+ 对抗样本（标签y）

    3. 调整损失函数（交叉熵损失），重新训练模型，迭代更新参数

    4. 验证集监控：正常样本准确率与对抗样本防御成功率

- 技术要点：对抗样本生成频率（每1~5个epoch更新一次）、学习率衰减策略（避免过拟合）

#### （3）简易对抗样本检测器

- 技术原理：基于模型推理时的置信度/特征异常，识别对抗样本

- 技术实现：

    - 置信度阈值法：统计正常样本的分类置信度分布，设定阈值，低于阈值则判定为对抗样本

    - 特征距离法：提取模型中间层特征（如ResNet50的avgpool输出），计算输入图像与正常样本特征库的欧氏距离，超出阈值则报警

- 技术要点：阈值需通过验证集校准，平衡误检率与漏检率

### 2. 防御效果技术验证

- 控制变量测试方案：

    - 固定攻击方法，调整攻击强度（ε值），测试防御前后的攻击成功率

    - 固定攻击强度，测试不同防御方法对FGSM/PGD/CW等攻击的防御效果

- 量化评估指标：

    - 防御成功率 = 1 - 防御后对抗样本误分类数量 / 测试集总数量

    - 正常样本准确率损失 = 防御后模型正常样本准确率 - 原始模型正常样本准确率

    - 计算开销：防御过程的额外耗时（如预处理耗时、检测器推理耗时）

## 四、黑盒迁移攻击技术实现

### 1. 迁移攻击技术框架

- 模型架构选型（确保差异显著）：

    - 源模型（生成对抗样本）：CNN类（如ResNet50）

    - 目标模型（测试攻击效果）：CNN类（如VGG19，与ResNet50卷积核设计差异）、Vision Transformer（ViT，无卷积层，基于注意力机制）

- 黑盒约束：目标模型仅提供输入→输出接口，不访问其参数、梯度或结构

### 2. 关键技术步骤

- 对抗样本生成（源模型侧）：

    - 使用FGSM/PGD/CW等方法，在源模型（白盒/灰盒）上生成对抗样本，保持扰动约束（ε值统一）

- 跨模型攻击测试（目标模型侧）：

    - 将生成的对抗样本输入目标模型，统计误分类数量，计算迁移攻击成功率

- 变量控制：

    - 保持对抗样本的扰动强度一致，避免因ε差异影响迁移效果对比

### 3. 技术分析要点

- 迁移性量化对比：

    - 不同攻击方法的迁移成功率（如PGD vs FGSM在ResNet50→ViT迁移中的表现）

    - 不同模型组合的迁移效果（ResNet50→VGG19 vs ResNet50→ViT）

- 架构相关性分析：

    - 特征提取方式差异影响：CNN的局部卷积特征 vs ViT的全局注意力特征，对迁移攻击的抗性差异

    - 模型复杂度影响：深层模型（ResNet50）生成的对抗样本，是否比浅层模型更易迁移

## 五、核心技术支撑与工具

### 1. 框架与工具选型

- 深度学习框架：PyTorch/TensorFlow（用于模型加载、梯度计算、攻击/防御代码实现）

- 图像处理工具：OpenCV/PIL（图像读取、预处理、可视化）

- 量化指标库：scikit-image（PSNR/SSIM计算）、numpy（张量运算）

- 模型权重：TorchVision/Hugging Face Transformers（预训练ResNet50、VGG19、ViT）

### 2. 代码模块化设计

- 攻击模块：封装每种攻击算法为独立函数（输入：原始图像、模型、参数→输出：对抗样本、攻击成功率）

- 防御模块：封装预处理/对抗训练/检测器为独立类（输入：图像/模型→输出：处理后图像/防御结果）

- 迁移测试模块：统一接口调用源模型生成样本、目标模型测试、结果统计

- 可视化模块：批量生成对比图、指标曲线、热力图

### 3. 关键代码技术要点

- 梯度计算：确保模型开启eval模式时仍能计算梯度（torch.set_grad_enabled(True)）

- 扰动约束：裁剪操作（torch.clamp）确保对抗样本像素值在合法范围

- 模型兼容：统一不同架构模型的输入输出格式（如ViT需调整图像分辨率为224×224）

- 可复现性：固定随机种子（numpy.random.seed、torch.manual_seed），确保实验结果可重复
> （注：文档部分内容可能由 AI 生成）